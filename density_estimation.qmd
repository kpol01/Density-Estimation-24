---
title: "Density Estimation"
subtitle: "Histograms, Asymptotics, Crossvalidation"
author: "Kaustav Paul 
      <br>
Shreya Chatterjee 
      <br>
      Ananyo Dey"
institute: Indian Statistical Institute, Delhi Center
Date: "2024.04.05"
format: 
  revealjs: 
    incremental: true
    code-fold: true
    transition: slide
    theme: moon
    fontsize: 180%
execute: 
  echo: true
editor: visual
---

## Introduction {.scrollable}

-   *Probability density function* is one of the vital and fundamental concept in statistics. Consider any random quantity $X$ that has a unique probability density function $f$. Guessing or knowing the $f$ is one of the important aspects for the statistician to infer about the population. It allows probabilities associated the $X$ to be found from the relation $$P(a < X <b) = \int_{a}^{b} f(x) dx \hspace{2mm} \text{for all} \hspace{2mm} a < b $$

-   One way of guessing about the $f$ is via parametric method. In this method we assume $f$ is a member of known parametric family of distribution and based on the observed data we are trying to estimate the parameters of the assuming parametric form.

-   Here we are focusing on the non-parametric approach with less rigid assumptions will be made about the distribution of the observed data.

-   Density estimation methods as we know them today began during the 1950s. However, in spirit it has been studied even via the Greeks via histograms.

# Estimators

-   We have to estimate density function $f$. But there does not exist any non-negative unbiased estimator of $f$. So all the estimators should be biased.

-   The very intuitive idea for estimating $f$ will be using histogram. For the presentation and exploration of data, histograms are of course an extremely useful class of density estimates, particularly in the *univariate case.*

-   Suppose $X_1, X_2, X_3, \cdots, X_n$ are iid $f(x)$ where $f(x)$ is completely unknown.

-   \textbf{Histogram With Fixed width :} Fix a point $x_0$ and a bin width $h$ . Consider histogram on the intervals $[x_0 + mh, x_0 + (m+1)h)$ where $m = 0, \pm 1, \pm 2, \pm 3, \cdots$ . Estimators of $f(x)$ = $\frac{1}{n h} \text{No. of} \hspace{1mm} X\text{'s in the same bin as} \hspace{1mm} x$

# Estimators

-   To construct that histogram, we have to choose both an origin and a bin width. Note, choosing the bin width primarily inherent the amount of smoothing.

-   From this estimators we can observe that if $n$ increases no. of $X$'s in the same bin as $x$ increases.

-   Let see some examples using simulation how the sample origin, bin width and sample size effects.

## Effects on Histogram

```{r,echo=FALSE,eval=TRUE,warning=FALSE}
rm(list = ls())

library(ggplot2)
library(gridExtra)
library(cowplot)

hist1 <- function(n, x0, h, rpdf, dens, alpha)      #if the simulating distribution has single argument
{
  set.seed(seed = 1)
  x <- rpdf(n, alpha)
  s<- seq(min(x)-h,max(x)+h,0.001)
  ds <- dens(s,alpha)
  fig <- ggplot() + geom_histogram(data = data.frame(x), aes(x = x, y = after_stat(density)),center=x0-h/2, binwidth=h, color="black", fill="white")  + 
    geom_line(data = data.frame(s, ds), aes(x = s, y = ds), color="red")
  return (fig)
}

hist2 <- function(n, x0, h, rpdf, dens, alpha, beta)      #if the simulating distribution has two arguments
{
  set.seed(seed = 1)
  x <- rpdf(n, alpha, beta)
  s <- seq(min(x)-h,max(x)+h,0.001)
  ds <- dens(s,alpha,beta)
  
  fig <- ggplot() + geom_histogram(data = data.frame(x), aes(x = x, y = after_stat(density)),center=x0-h/2, binwidth=h, color="black", fill="white")  + 
    geom_line(data = data.frame(s, ds), aes(x = s, y = ds), color="red")
  return (fig)
}


hist_comp_origin1 <- function(n, origin, h, rpdf, dens, alpha)
{
  plots <- list()
  for(i in (1:length(origin)))
  {
    plots[[i]] <- hist1(n, origin[i], h, rpdf, dens, alpha)+labs(title = paste("x_0 = ", origin[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(origin)/2))
}

hist_comp_origin2 <- function(n, origin, h, rpdf, dens, alpha, beta)
{
  plots <- list()
  for(i in (1:length(origin)))
  {
    plots[[i]] <- hist2(n, origin[i], h, rpdf, dens, alpha, beta)+labs(title = paste("x_0 = ", origin[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(origin)/2))
}
```

## Effect of Origin (x_0) on Histogram

#### For Symmetric Distribution

```{r}
norm_origin <- hist_comp_origin2(50, c(-0.3,0,0.3,0.6), 0.5, rnorm, dnorm, 0, 1)
title <- ggdraw() + draw_label("N(0,1) with n=50, h=0.5",fontface = 'bold')
plot_grid(title, norm_origin,ncol = 1,rel_heights = c(0.1, 1))

```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $N(0,1)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the Histogram $n$ as 50 and bin width of all the bin $h$ as $0.1$
2.  Histograms show that as $x_0$ shifts **Normal** shifts accordingly.

------------------------------------------------------------------------

#### For Positively Skewed Distribution

```{r}
exp_origin <- hist_comp_origin1(50, c(-0.2,0,0.6,0.8), 0.5, rexp, dexp, 1)
title <- ggdraw() + draw_label("exp(1) with n = 50s, h = 0.5",fontface = 'bold')
plot_grid(title, exp_origin,ncol = 1,rel_heights = c(0.1, 1))

```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $exponential (1)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the Histogram $n$ as 50 and bin width of all the bin $h$ as $0.5$
2.  Histograms show that as $x_0$ shifts **Exponential** shifts in the right side as it *non-negative* distribution and depends on the origin.

------------------------------------------------------------------------

#### For Negatively Skewed Distribution

```{r}
beta_origin <- hist_comp_origin2(50, c(-0.256,0.355,0.62,0.832), 0.1, rbeta, dbeta, 5, 2)
title <- ggdraw() + draw_label("Beta(5,2) with n = 50, h = 0.1",fontface = 'bold')
plot_grid(title, beta_origin,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $beta(5,2)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the Histogram $n$ as 50 and bin width of all the bin $h$ as $0.1$
2.  Histograms show that as $x_0$ shifts **Beta** shifts right side also but in low sample size the fit is pretty bad and very much depend on the origin.

------------------------------------------------------------------------

#### For Bimodal Distribution

```{r}
hist_mix_norms <- function(n,x0,h,m1,s1,m2,s2,p){
  set.seed(seed=1)
  y <- rnorm(n*p,m1,s1)
  z <- rnorm(n*(1-p),m2,s2)
  x <- c(y,z[z!=y])
  s<- seq(min(x)-0.5,max(x)+0.5,0.1)
  ds <- p*dnorm(s,m1,s1)+(1-p)*dnorm(s,m2,s2)
  ggplot() + geom_histogram(data = data.frame(x), aes(x = x, y = after_stat(density)),center=x0-h/2, binwidth=h, color="black", fill="white")  + 
    geom_line(data = data.frame(s, ds), aes(x = s, y = ds), color="red")
}

hist_comp_origin3 <- function(n, origin, h, m1,s1,m2,s2,p)
{
  plots <- list()
  for(i in (1:length(origin)))
  {
    plots[[i]] <- hist_mix_norms(n, origin[i], h, m1,s1,m2,s2,p)+labs(title = paste("x_0 = ", origin[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(origin)/2))
}

normmix_origin <- hist_comp_origin3(50,c(-0.3,0,0.3,0.6),1,-5,1,4,3,0.3)
title <- ggdraw() + draw_label("0.3*N(-5,1)+0.7*N(4,3) with n = 50, h = 1",fontface = 'bold')
plot_grid(title, normmix_origin,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from Mixture of two Normal distribution, $N(-5,1)$ and $N(4,3)$ with mixture parameter $0.3$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the Histogram $n$ as 50 and bin width of all the bin $h$ as $0.5$
2.  Histograms show that as $x_0$ shifts **Mixture distribution** shifts accordingly and being highly effected by origin change.

------------------------------------------------------------------------

#### For Discrete Distribution

```{r,warning=FALSE}
geo_origin <- hist_comp_origin1(500,c(5,5.3,5.5,5.7),1, rgeom, dgeom,0.3)
title <- ggdraw() + draw_label("Geometric(0.3) with n = 500, h = 1",fontface = 'bold')
plot_grid(title, geo_origin,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from Geometric$(0.3)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the Histogram $n$ as 500 and bin width of all the bin $h$ as $1$
2.  Histograms show that as $x_0$ shifts **Geometric distribution** shifts accordingly.

------------------------------------------------------------------------

### Effect of Fixed bin width (h) on Histogram

```{r}
hist_comp_width1 <- function(n, x0, width, rpdf, dens, alpha)
{
  plots <- list()
  for(i in (1:length(width)))
  {
    plots[[i]] <- hist1(n, x0, width[i], rpdf, dens, alpha)+labs(title = paste("h = ", width[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(width)/2))
}

hist_comp_width2 <- function(n, x0, width, rpdf, dens, alpha, beta)
{
  plots <- list()
  for(i in (1:length(width)))
  {
    plots[[i]] <- hist2(n, x0, width[i], rpdf, dens, alpha, beta)+labs(title = paste("h = ", width[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(width)/2))
}
```

#### For Symmetric Distribution

```{r}
norm_width <- hist_comp_width2(500, 0, c(0.3,0.5,0.7,1), rnorm, dnorm, 0, 1)
title <- ggdraw() + draw_label("N(0,1) with n = 500, x_0 = 0",fontface = 'bold')
plot_grid(title, norm_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $N(0,1)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the histogram $n$ as 500 and origin $x_0$ as 0.
2.  Histograms show that as $h$ increases the amount of precision for **Normal** distribution decreases.

------------------------------------------------------------------------

#### For Positively Skewed Distribution

```{r}
exp_width <- hist_comp_width1(100, 0, c(0.3,0.5,0.7,1), rexp, dexp, 1)
title <- ggdraw() + draw_label("exp(1) with n = 100, x_0 = 0",fontface = 'bold')
plot_grid(title, exp_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $exponential(1)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the histogram $n$ as 100 and origin $x_0$ as 0.
2.  Histograms show that as $h$ increases the amount of precision for **Exponential** distribution decreases.

------------------------------------------------------------------------

#### For Negatively Skewed Distribution

```{r}
beta_width <- hist_comp_width2(500, 0, c(0.2,0.1,0.05,0.03), rbeta, dbeta, 5, 2)
title <- ggdraw() + draw_label("Beta(5,2) with n=500, x_0 = 0",fontface = 'bold')
plot_grid(title, beta_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $beta(5,2)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the histogram $n$ as 500 and origin $x_0$ as 0.
2.  Histograms show that as $h$ increases the amount of precision for **Beta** distribution much decreases.

------------------------------------------------------------------------

#### For Bimodal Distribution

```{r}

hist_comp_width3 <- function(n, x0, width, m1,s1,m2,s2,p)
{
  plots <- list()
  for(i in (1:length(width)))
  {
    plots[[i]] <- hist_mix_norms(n, x0, width[i], m1,s1,m2,s2,p)+labs(title = paste("h = ", width[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(width)/2))
}

normmix_width <- hist_comp_width3(500,0,c(2,1,0.5,0.3),-5,1,4,3,0.3)
title <- ggdraw() + draw_label("0.3*N(-5,1)+0.7*N(4,3) with n=500, x_0 = 0",fontface = 'bold')
plot_grid(title, normmix_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

#### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from Mixture of two Normal distribution, $N(-5,1)$ and $N(4,3)$ with mixture parameter $0.3$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Consider sample size of the histogram $n$ as 500 and origin $x_0$ as 0.
2.  Histograms show that as $h$ increases the amount of precision for **Mixture** distribution decreases.

------------------------------------------------------------------------

#### For Discrete Distribution

```{r, warning=FALSE}
geo_width <- hist_comp_width1(100,5.5,c(0.7,1,2,3), rgeom, dgeom,0.3)
title <- ggdraw() + draw_label("Geometric(0.3) with n = 100, x_0 = 5.5",fontface = 'bold')
plot_grid(title, geo_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

1.  

------------------------------------------------------------------------

```{r}

hist_comp_size1 <- function(samp, x0, h, rpdf, dens, alpha)
{
  plots <- list()
  for(i in (1:length(samp)))
  {
    plots[[i]] <- hist1(samp[i], x0, h, rpdf, dens, alpha)+labs(title = paste("n = ", samp[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(samp)/2))
}

hist_comp_size2 <- function(samp, x0, h, rpdf, dens, alpha, beta)
{
  plots <- list()
  for(i in (1:length(samp)))
  {
    plots[[i]] <- hist2(samp[i], x0, h, rpdf, dens, alpha, beta)+labs(title = paste("n = ", samp[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(samp)/2))
}
```

### Effect of Sample size (n) on Histogram

#### For symmetric Distribution

```{r}
norm_size <- hist_comp_size2(c(50,100,500,1000), 0, 0.5, rnorm, dnorm, 0, 1)
title <- ggdraw() + draw_label("N(0,1) with x_0 = 0, h = 0.5",fontface = 'bold')
plot_grid(title, norm_size,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $N(0,1)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Considering origin $x_0$ of the Histogram as 0 and bin width of all the bin $h$ as $0.5$
2.  Histograms show that as $n$ increases the amount of smoothing of **Normal** density increases.

------------------------------------------------------------------------

#### For Positively skewed Distribution

```{r}

exp_size <- hist_comp_size1(c(50,100,500,1000), 0, 0.2, rexp, dexp, 1)
title <- ggdraw() + draw_label("exp(1) with x_0 = 0, h = 0.2",fontface = 'bold')
plot_grid(title, exp_size,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $exponential(1)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Considering origin $x_0$ of the Histogram as 0 and bin width of all the bin $h$ as $0.2$
2.  Histograms show that as $n$ increases the amount of smoothing of **Exponential** density increases.

------------------------------------------------------------------------

#### For Negatively Skewed Distribution

```{r}
beta_size <- hist_comp_size2(c(50,100,500,1000), 0, 0.06, rbeta, dbeta, 5, 2)
title <- ggdraw() + draw_label("Beta(5,2) with x_0 = 0, h = 0.06",fontface = 'bold')
plot_grid(title, beta_size,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from $beta(5,2)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Considering origin $x_0$ of the Histogram as 0 and bin width of all the bin $h$ as $0.06$
2.  Histograms show that as $n$ increases the amount of smoothing of **Beta** density increases.

------------------------------------------------------------------------

#### For Bimodal Distribution

```{r}

hist_comp_size3 <- function(samp, x0, h, m1,s1,m2,s2,p)
{
  plots <- list()
  for(i in (1:length(samp)))
  {
    plots[[i]] <- hist_mix_norms(samp[i], x0, h, m1,s1,m2,s2,p)+labs(title = paste("n = ", samp[i]))
  }
  grid.arrange(grobs = plots, ncol = round(length(samp)/2))
}

normmix_size <- hist_comp_size3(c(50,100,500,1000),0,0.5,-5,1,4,3,0.3)
title <- ggdraw() + draw_label("0.3*N(-5,1)+0.7*N(4,3) with x_0 = 0, h = 0.5",fontface = 'bold')
plot_grid(title, normmix_size,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from a mixture distribution of $N(-5,1)$ and $N(4,3)$ with mixture parameter $p = 0.3$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Considering origin $x_0$ of the Histogram as 0 and bin width of all the bin $h$ as $0.5$
2.  Histograms show that as $n$ increases the amount of smoothing of **Mixture** **Normal** density increases.

------------------------------------------------------------------------

#### For Discrete Distribution

```{r, warning=FALSE}

geo_size <- hist_comp_size1(c(100,200,500,1000), 5.5 ,1, rgeom, dgeom,0.3)
title <- ggdraw() + draw_label("Geometric(0.3) with x_0 = 5.5, h = 1",fontface = 'bold')
plot_grid(title, geo_size,ncol = 1,rel_heights = c(0.1, 1))

```

------------------------------------------------------------------------

##### Comments:

From the above figure,

1.  $X_1, X_2, \cdots, X_n$ are chosen from Geometric$(0.3)$. Assuming their density to be unknown we are trying to estimate the density using *Histogram.* Considering origin $x_0$ of the Histogram as 5.5 and bin width of all the bin $h$ as $1$

2.  Histograms show that as $n$ increases the amount of smoothing of **Geometric** density increases.

------------------------------------------------------------------------

# Estimators

-   Histogram can be generalized by allowing bandwidths to vary. So here we consider the varying bandwidth. This varying bindwidth could be decided aprior or be data depended. We can estimate density by: $$\hat{f_2(x)} = \frac{1}{n} \frac{\text{No. of X's in the same bin as x}}{\text{width of the bin}}$$

-   Lets see how it goes via simulation

# Effects on Histograms

```{r}
hist4 <- function(n,h, rpdf, dens, alpha)      #if the simulating distribution has single argument
{
  set.seed(seed = 1)
  x <- rpdf(n, alpha)
  s<- seq(min(h),max(h),0.001)
  ds <- dens(s,alpha)
  fig <- ggplot() + geom_histogram(data = data.frame(x), aes(x = x, y = after_stat(density)),breaks=h, color="black", fill="grey")  + 
    geom_line(data = data.frame(s, ds), aes(x = s, y = ds), color="red")
  return (fig)
}

hist5 <- function(n, h, rpdf, dens, alpha, beta)      #if the simulating distribution has two arguments
{
  set.seed(seed = 1)
  x <- rpdf(n, alpha, beta)
  s <- seq(min(h),max(h),0.001)
  ds <- dens(s,alpha,beta)
  
  fig <- ggplot() + geom_histogram(data = data.frame(x), aes(x = x, y = after_stat(density)),breaks=h, color="black", fill="grey")  + 
    geom_line(data = data.frame(s, ds), aes(x = s, y = ds), color="red")
  return (fig)
}

hist_mix6 <- function(n,h,m1,s1,m2,s2,p){
  set.seed(seed=1)
  y <- rnorm(n*p,m1,s1)
  z <- rnorm(n*(1-p),m2,s2)
  x <- c(y,z[z!=y])
  s<- seq(min(h),max(h),0.1)
  ds <- p*dnorm(s,m1,s1)+(1-p)*dnorm(s,m2,s2)
  ggplot() + geom_histogram(data = data.frame(x), aes(x = x, y = after_stat(density)),breaks=h, binwidth=h, color="black", fill="grey")  + 
    geom_line(data = data.frame(s, ds), aes(x = s, y = ds),color="red")
}

#For varying width (binwidth are unequal)
hist_comp_width4 <- function(n, width, rpdf, dens, alpha)
{
  plots <- list()
  for(i in (1:length(width)))
  {
    plots[[i]] <- hist4(n, width[[i]], rpdf, dens, alpha)+labs(title = paste(c("h = ", round(width[[i]],2)), collapse=",",sep=","))
  }
  grid.arrange(grobs = plots, ncol = round(length(width)/2))
}


hist_comp_width5 <- function(n, width, rpdf, dens, alpha, beta)
{
  plots <- list()
  for(i in (1:length(width)))
  {
    plots[[i]] <- hist5(n, width[[i]], rpdf, dens, alpha, beta)+labs(title = paste(c("h = ", round(width[[i]],2)), collapse=",",sep=","))
  }
  grid.arrange(grobs = plots, ncol = round(length(width)/2))
}

hist_comp_width6 <- function(n, width, m1,s1,m2,s2,p)
{
  plots <- list()
  for(i in (1:length(width)))
  {
    plots[[i]] <- hist_mix6(n, width[[i]], m1,s1,m2,s2,p)+labs(title = paste(c("h = ", round(width[[i]],2)), collapse=" ,",sep=","))
  }
  grid.arrange(grobs = plots, ncol = round(length(width)/2))
}
```

------------------------------------------------------------------------

### Effects of varying width on Histogram

#### For Symmetric distribution

```{r}
v<-c()
for(i in 3:8){
  v <- sort(c(v, 5/sqrt(prod(3:i))))
}
v<- sort(c(v,-v,0))
breaks <- list(v,c(-3,-1.5,-0.5,0,0.5,1.5,3),c(-3,-1.5,-0.5,v[c(7:13)]),v[-c(1:2,12:13)]*8)
norm_width <- hist_comp_width5(500, breaks, rnorm, dnorm, 0, 1)
title <- ggdraw() + draw_label("N(0,1) with n=500, x0=0",fontface = 'bold')
plot_grid(title, norm_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

1.  

------------------------------------------------------------------------

#### For Positively Skewed distribution

```{r}
v<-c(0)
for(i in 1:7){
  v <- sort(c(v, 4/sqrt(prod(1:i))))
}
breaks <- list(v,v*2,v[-c(7:8)]*3,v[-c(7:8)]*4)
exp_width <- hist_comp_width4(500, breaks, rexp, dexp, 1)
title <- ggdraw() + draw_label("exp(1) with n = 500,x_0 = 0",fontface = 'bold')
plot_grid(title, exp_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

1.  

------------------------------------------------------------------------

#### For Negatively Skewed distribution

```{r}
v<- c(0.05,0.15,0.35,0.5,0.75,1.05,1.4,1.8)
breaks <- list(v,v*1.3,v*1.2,v*0.75)
beta_width <- hist_comp_width5(500, breaks, rbeta, dbeta, 5, 2)
title <- ggdraw() + draw_label("Beta(5,2) with n=500, x0=0",fontface = 'bold')
plot_grid(title, beta_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

1.  

------------------------------------------------------------------------

#### For Bimodal distribution

```{r,warning=FALSE}
v<-c()
for(i in 3:7){
  v <- sort(c(v, 1/sqrt(prod(3:i))))
}
v<- sort(c(v,-v,0))
breaks <- list(c(30*v),c(20*v),c(-5+12*v, 4+9*v),c(-5+7*v, 4+3*v))
normmix_width <- hist_comp_width6(1000,breaks,-5,1,4,3,0.3)
title <- ggdraw() + draw_label("0.3*N(-5,1)+0.7*N(4,3) with n=1000, x0=0",fontface = 'bold')
plot_grid(title, normmix_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

1.  

------------------------------------------------------------------------

#### For Discrete distribution

```{r, warning=FALSE}
v<- c(0.5,1.5,3,5,7.5,10.5)
breaks <- list(v,v*2,v*0.5,v*0.75)
geo_width <- hist_comp_width4(1000,breaks, rgeom, dgeom,0.3)
title <- ggdraw() + draw_label("Geometric(0.3) with n = 1000, x_0 = 5.5",fontface = 'bold')
plot_grid(title, geo_width,ncol = 1,rel_heights = c(0.1, 1))
```

------------------------------------------------------------------------

##### Comments:

1.  

# Asymptotic Normality Checking

## Background Theory

Kernel type Estimator: Consider the class of estimators of the form, $$f_n(x) = \frac{1}{nh_n} \sum_{i=1}^n k(\frac{x-X_i}{h_n})$$ where $h_n \rightarrow 0$ and $n \rightarrow \infty$ and $K$ is a suitable density function, i.e., $A_1:$ sup $\{k(x) : x \in \mathbb{R}\} \leq M$, $|x|k(x) \rightarrow 0$ as $|x| \rightarrow \infty$ \$A_2: \$ $k(x) = k(-x) \hspace{2mm} \forall x$ $\int_{-\infty}^{\infty} x^2 k(x) dx < \infty$

Now applying the large sample theory, Under some regularity condition, $$\frac{f_n(x) - \mathbb{E}(f_n(x))}{\sqrt{Var(f_n(x))}} \xrightarrow[]{\mathcal{D}} N(0,1)$$ as $n \rightarrow \infty$ Note: $\mathbb{E}(f_n(x)) = \frac{1}{h_n} \int_{-\infty}^{\infty} k(\frac{x-y}{h_n}) f(y) dy$ and var$(f_n(x)) \approx \frac{1}{h_n} f(x) \int_{-\infty}^{\infty} k^2(z) dz$

## Inter-play between $n$ and $h_n$

#### Points to be noted

::: incremental
-   With decrease in $h_n$ results are expected to more precise.
-   The asymptotic variance of $f_n(x)$ is of order $nh_n$, hence $nh_n$ is the right scaling factor for $(f_n(x) - f(x))$.
-   For asymptotic results to hold we need $h_n \rightarrow 0$ and $nh_n \rightarrow \infty$
-   To achieve normality we not only need $n$ to be large but $nh_n$ to be large as well.
-   So depending on the choice of $n$ we need to choose $h_n$. Hence $h_n$ also plays a role in the asymptotic behaviour of $f_n(x)$.
-   To be precise, if we have a small $n$ $h_n$ needs to be of smaller order than $h_n$ required for larger $n$ to attain asymptotic normality.
:::

## Inter-play between $n$ and $h_n$ {.scrollable}

#### Samples from N(0,1), with *Gaussian kernel*, taking $h_n = n^{-0.1}, n^{-0.2}, n^{-0.3}, n^{-0.4}$

```{r, echo = F, fig.height=5, include=F}
library(ggplot2)
library(gridExtra)

# Define the kernel functions
gaussian_kernel <- function(u) dnorm(u)
logistic_kernel <- function(u) dlogis(u)
naive_kernel <- function(u) ifelse(abs(u) <= 1, 0.5, 0)
tricube_kernel <- function(u) ifelse(abs(u) <= 1, 35/32 * (1 - abs(u)^3)^3, 0)
cosine_kernel <- function(u) ifelse(abs(u) <= 1, pi/4 * cos(pi/2 * u), 0)
epanechnikov_kernel <- function(u) ifelse(abs(u) <= 1, 3/4 * (1 - u^2), 0)

# Set the values for n and calculate h_n for each
n_values <- c(20, 50, 100, 250, 500)

n<-5000
n_values <- rep(n, 4)
h_values <- c(n ^ (-0.1), n^(-0.2) , n^(-0.3), n^(-0.4))


# Function to simulate and plot for a given kernel

simulate_and_plot <- function(kernel_func, kernel_name, quantile, n) {
  
  n_values <- rep(n, 4)
  h_values <- c(n ^ (-0.1), n^(-0.2) , n^(-0.3), n^(-0.4))
  p <- list()
  for (i in (1:length(n_values))) {
    n <- n_values[i]
    h <- h_values[i]
    
    # Generate random samples
    
    
    # Compute the 0.1 quantile of the sample
    x_q <- qnorm(quantile, 0, 1)
    
    # For each sample, estimate the density at x_q using the kernel function
    f_n_x <- replicate(1000, {
      sample_x_i <- rnorm(n,0,1)          # New sample for each replication
      mean(kernel_func((x_q - sample_x_i) / h)) / h
    })
    
    
    df<-D(D(expression(1/sqrt(2*pi)*exp(-0.5*x^2)),"x"),"x")
    mode(df)
    x<-x_q
    E_f_n_x <- dnorm(x_q,0,1)+ (0.5 * h^2 * eval(df))
    kernel_int <- integrate(function(u) kernel_func(u)^2, lower = -Inf, upper = Inf)$value
    var_f_n_x <- (1 / (n * h)) * dnorm(x_q,0,1) * kernel_int
    
    # Standardize f_n(x)
    standardized_f_n_x <- (f_n_x-E_f_n_x)/sqrt( var_f_n_x)
    
    # Create a dataframe for plotting
    data_to_plot <- data.frame(standardized_f_n_x = standardized_f_n_x)
    
    # Plot the histogram with the density of N(0,1) overlaid
    
    
    p[[i]] <- ggplot(data_to_plot, aes(x = standardized_f_n_x)) +
      geom_histogram(aes(y = ..density..), bins = 30, color = "black", fill = "skyblue") +
      stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = "red", size = 1) +
      labs(title = paste("| n =", n, "| h_n =", round(h, 3)),
           x = "Standardized f_n(x_q)", y = "Density")
    
  }
  return(p)
}

p1 <- grid.arrange(grobs = simulate_and_plot(gaussian_kernel, "Gaussian", 0.5, 20), nrow = 1)
p2 <- grid.arrange(grobs = simulate_and_plot(gaussian_kernel, "Gaussian", 0.5, 100), nrow = 1)
p3 <- grid.arrange(grobs = simulate_and_plot(gaussian_kernel, "Gaussian", 0.5, 500), nrow = 1)


```

::: incremental
```{r, echo = F, fig.height=5}
grid.arrange(grobs = list(p1, p2, p3), ncol = 1)
```
:::

## Inter-play between $n$ and $h_n$

#### Observations

::: incremental
-   For large $n$ we need $h_n$ of very small orders to attain asymptotic normality.
-   For $n = 20$, even $h_n = n ^{-0.4}$ there are some disturbances with the peak of the histograms.
-   Where as for $n = 500$, with $h_n = n ^ {-0.2}$ we get similar results that we get with $h_n = n ^ {-0.4} for n = 20$
-   $nh_n$ determines the rate of convergence of $f_n(x) - f(x)$ to asymptotic normality.
:::

# Least Square Cross Validation

It is a data based method for choosing $h_n$. 

Let $f_{n}(x)$ be an estimator of the unknown density $f$. 
$$f_n(x) = \frac{1}{nh_n} \sum_{i=1}^n k(\frac{x-X_i}{h_n})$$ 
The Integrated Squared Error is defined as, ISE = $\int_{-\infty}^{\infty}(f_n(x)-f(x))^2 dx$.
Minimising ISE w.r.t $h_n$ is equivalent to minimising $M_0(h_n)=\int_{-\infty}^{\infty}(f_n^2(x)dx-\frac{2}{n}\sum_{i=1}^{n}\hat{f}_{-i}(X_i)$ w.r.t $h_n$, where $\hat{f}_{-i}(X_i)= \frac{1}{(n-1)h_n}\sum_{j=1}^{n}k(\frac{x-X_j}{h_n})$
Usage of the optimal $h_n$ obtained by this minimisation, would help us in checking asymptotic normality.
